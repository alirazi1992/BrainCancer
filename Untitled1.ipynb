{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "013b55be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.26.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "import itertools\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from plotly import tools\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras import layers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "RANDOM_SEED = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "650ef599",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no', 'yes']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/Users/alirazi/Desktop/archive/brain_tumor_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71544a79",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m im \u001b[38;5;241m=\u001b[39m\u001b[43mImage\u001b[49m\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/alirazi/Desktop/archive/brain_tumor_dataset/no/1 no.jpeg\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mresize((\u001b[38;5;241m128\u001b[39m,\u001b[38;5;241m128\u001b[39m))\n\u001b[1;32m      2\u001b[0m im\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "im =Image.open('/Users/alirazi/Desktop/archive/brain_tumor_dataset/no/1 no.jpeg').resize((128,128))\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de343c01",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m im \u001b[38;5;241m=\u001b[39m\u001b[43mImage\u001b[49m\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/alirazi/Desktop/archive/brain_tumor_dataset/no/21 no.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mresize((\u001b[38;5;241m128\u001b[39m,\u001b[38;5;241m128\u001b[39m))\n\u001b[1;32m      2\u001b[0m im\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "im =Image.open('/Users/alirazi/Desktop/archive/brain_tumor_dataset/no/21 no.jpg').resize((128,128))\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40522a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Specify the full and absolute paths to the 'yes' and 'no' directories\n",
    "yes_dir = '/Users/alirazi/Desktop/archive/brain_tumor_dataset/yes'\n",
    "no_dir = '/Users/alirazi/Desktop/archive/brain_tumor_dataset/no'\n",
    "\n",
    "# Use os.listdir() to get a list of files in each directory\n",
    "yes_images = os.listdir(yes_dir)\n",
    "no_images = os.listdir(no_dir)\n",
    "\n",
    "# Now 'yes_images' and 'no_images' contain the list of image filenames in their respective directories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2581c22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenation successful.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the full paths to the 'yes' and 'no' directories\n",
    "yes_dir = '/Users/alirazi/Desktop/archive/brain_tumor_dataset/yes'\n",
    "no_dir = '/Users/alirazi/Desktop/archive/brain_tumor_dataset/no'\n",
    "\n",
    "# Use os.listdir() to get lists of image filenames in each directory\n",
    "yes_images = os.listdir(yes_dir)\n",
    "no_images = os.listdir(no_dir)\n",
    "\n",
    "# Concatenate the lists into a single 'data' variable\n",
    "data = np.concatenate([yes_images, no_images])\n",
    "\n",
    "# Check if the length of 'data' is equal to the sum of the lengths of 'yes_images' and 'no_images'\n",
    "if len(data) == len(yes_images) + len(no_images):\n",
    "    print(\"Concatenation successful.\")\n",
    "else:\n",
    "    print(\"Concatenation failed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a43875ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenation successful.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define the full paths to the 'yes' and 'no' directories\n",
    "yes_dir = '/Users/alirazi/Desktop/archive/brain_tumor_dataset/yes'\n",
    "no_dir = '/Users/alirazi/Desktop/archive/brain_tumor_dataset/no'\n",
    "\n",
    "# Use os.listdir() to get lists of image filenames in each directory\n",
    "yes_images = os.listdir(yes_dir)\n",
    "no_images = os.listdir(no_dir)\n",
    "\n",
    "# Define target arrays based on the lengths of 'yes_images' and 'no_images'\n",
    "target_x = np.full(len(yes_images), 1)\n",
    "target_y = np.full(len(no_images), 0)\n",
    "\n",
    "# Concatenate the target arrays to create 'data_target'\n",
    "data_target = np.concatenate([target_x, target_y])\n",
    "\n",
    "# Check if the length of 'data_target' is equal to the sum of the lengths of 'target_x' and 'target_y'\n",
    "if len(data_target) == len(target_x) + len(target_y):\n",
    "    print(\"Concatenation successful.\")\n",
    "else:\n",
    "    print(\"Concatenation failed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e4e588e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_target)==len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a4058be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0e1d06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Y157.JPG', 'Y6.jpg', 'Y194.jpg', 'Y180.jpg', 'Y90.jpg', 'Y47.JPG',\n",
       "       'Y53.jpg', 'Y52.jpg', 'Y46.jpg', 'Y91.jpg', 'Y85.JPG', 'Y181.jpg',\n",
       "       'Y195.JPG', 'Y7.jpg', 'Y156.JPG', 'Y168.jpg', 'Y154.jpg',\n",
       "       'Y183.jpg', 'Y78.jpg', 'Y50.JPG', 'Y44.JPG', 'Y45.JPG', 'Y51.jpg',\n",
       "       'Y79.jpg', 'Y86.JPG', 'Y92.jpg', 'Y92.png', 'Y182.JPG', 'Y155.JPG',\n",
       "       'Y4.jpg', 'Y169.jpg', 'Y186.jpg', 'Y192.JPG', 'Y96.jpg', 'Y82.jpg',\n",
       "       'Y55.jpg', 'Y41.jpg', 'Y69.jpg', 'Y40.JPG', 'Y54.jpg', 'Y97.JPG',\n",
       "       'Y193.JPG', 'Y187.jpg', 'Y1.jpg', 'Y3.jpg', 'Y146.JPG', 'Y185.jpg',\n",
       "       'Y81.jpg', 'Y95.jpg', 'Y42.jpg', 'Y56.jpg', 'Y184.JPG', 'Y2.jpg',\n",
       "       'Y147.JPG', 'Y153.jpg', 'Y108.jpg', 'Y120.JPG', 'Y242.JPG',\n",
       "       'Y256.JPG', 'Y18.JPG', 'Y24.jpg', 'Y30.jpg', 'Y31.jpg', 'Y25.jpg',\n",
       "       'Y19.JPG', 'Y257.jpg', 'Y243.JPG', 'Y109.JPG', 'Y255.JPG',\n",
       "       'Y33.jpg', 'Y27.jpg', 'Y26.jpg', 'Y32.jpg', 'Y254.jpg', 'Y250.jpg',\n",
       "       'Y244.JPG', 'Y36.JPG', 'Y22.jpg', 'Y23.JPG', 'Y37.jpg', 'Y245.jpg',\n",
       "       'Y251.JPG', 'Y247.JPG', 'Y253.JPG', 'Y21.jpg', 'Y35.jpg',\n",
       "       'Y34.jpg', 'Y20.jpg', 'Y252.jpg', 'Y246.JPG', 'Y115.JPG',\n",
       "       'Y101.jpg', 'Y39.jpg', 'Y11.jpg', 'Y10.jpg', 'Y38.jpg', 'Y100.JPG',\n",
       "       'Y114.JPG', 'Y102.jpg', 'Y116.JPG', 'Y248.JPG', 'Y12.jpg',\n",
       "       'Y13.jpg', 'Y249.JPG', 'Y117.JPG', 'Y103.jpg', 'Y107.jpg',\n",
       "       'Y113.JPG', 'Y259.JPG', 'Y17.jpg', 'Y16.JPG', 'Y258.JPG',\n",
       "       'Y112.JPG', 'Y106.jpg', 'Y104.jpg', 'Y14.jpg', 'Y28.jpg',\n",
       "       'Y29.jpg', 'Y15.jpg', 'Y105.jpg', 'Y111.JPG', 'Y162.jpg',\n",
       "       'Y99.JPG', 'Y66.JPG', 'Y73.jpg', 'Y67.JPG', 'Y98.JPG', 'Y188.jpg',\n",
       "       'Y163.JPG', 'Y161.JPG', 'Y59.JPG', 'Y71.JPG', 'Y65.JPG', 'Y70.jpg',\n",
       "       'Y58.JPG', 'Y160.JPG', 'Y148.JPG', 'Y164.JPG', 'Y170.JPG',\n",
       "       'Y158.JPG', 'Y9.jpg', 'Y74.jpg', 'Y60.jpg', 'Y49.JPG', 'Y61.jpg',\n",
       "       'Y75.JPG', 'Y8.jpg', 'Y159.JPG', 'Y165.JPG', 'Y167.JPG', 'Y77.jpg',\n",
       "       'Y76.jpg', 'Y62.jpg', 'Y89.JPG', 'Y166.JPG', '30 no.jpg',\n",
       "       '22 no.jpg', '41 no.jpg', '14 no.jpg', 'no 10.jpg', '18 no.jpg',\n",
       "       'no 9.png', 'no 7.jpeg', 'no 8.jpg', 'no.jpg', '3 no.jpg',\n",
       "       '43 no.jpg', '20 no.jpg', '32 no.jpg', '2 no.jpeg', 'N15.jpg',\n",
       "       'no 99.jpg', 'no 98.jpg', 'No11.jpg', '7 no.jpg', '12 no.jpg',\n",
       "       'No13.jpg', '44no.jpg', 'N16.jpg', 'N17.jpg', '28 no.jpg',\n",
       "       '36 no.jpg', 'No12.jpg', '47 no.jpg', '24 no.jpg', 'No16.jpg',\n",
       "       '10 no.jpg', '26 no.jpg', '45 no.jpg', 'no 923.jpg', '38 no.jpg',\n",
       "       'No17.jpg', '49 no.jpg', '34 no.jpg', '1 no.jpeg', 'no 100.jpg',\n",
       "       'No15.jpg', '5 no.jpg', 'N11.jpg', 'no 89.jpg', 'No14.jpg',\n",
       "       '9 no.jpg', 'No19.jpg', 'no 90.jpg', 'N20.JPG', 'N21.jpg',\n",
       "       'No18.jpg', '15 no.jpg', '19 no.jpg', 'N22.JPG', 'no 92.jpg',\n",
       "       '31 no.jpg', '40 no.jpg', '23 no.jpg', '17 no.jpg', 'N26.JPG',\n",
       "       'no 96.jpg', 'no 97.jpg', '21 no.jpg', '42 no.jpg', 'No22.jpg',\n",
       "       '33 no.jpg', '50 no.jpg', 'No20.jpg', 'no 95.jpg', 'N19.JPG',\n",
       "       'no 94.jpg', 'No21.jpg', '37 no.jpg', 'N6.jpg', '29 no.jpg',\n",
       "       '25 no.jpg', 'no 91.jpeg', 'no 3.jpg', '46 no.jpg', 'no 2.jpg',\n",
       "       '13 no.jpg', 'N5.jpg', '6 no.jpg', 'no 1.jpg', 'no 5.jpeg',\n",
       "       '4 no.jpg', '8 no.jpg', 'no 4.jpg', 'N1.JPG', '39 no.jpg',\n",
       "       'N3.jpg', '27 no.jpg', '35 no.jpg', 'no 6.jpg', '48 no.jpeg',\n",
       "       '11 no.jpg', 'N2.JPG'], dtype='<U10')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dac06c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_values=os.listdir('/Users/alirazi/Desktop/archive/brain_tumor_dataset/yes')\n",
    "no_values=os.listdir('/Users/alirazi/Desktop/archive/brain_tumor_dataset/no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4955dfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = []\n",
    "\n",
    "# Assuming 'yes_values' contains the list of filenames in the 'yes' directory\n",
    "for file in yes_values:\n",
    "    # Construct the full path to the image file by adding '/' between the directory path and filename\n",
    "    img_path = '/Users/alirazi/Desktop/archive/brain_tumor_dataset/yes/' + file\n",
    "\n",
    "    # Read the image using OpenCV\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    # Check if the image was successfully loaded\n",
    "    if img is not None:\n",
    "        # Resize the image\n",
    "        face = cv2.resize(img, (32, 32))\n",
    "        \n",
    "        # Split channels and merge them in the correct order (BGR to RGB)\n",
    "        (b, g, r) = cv2.split(face)\n",
    "        img = cv2.merge([r, g, b])\n",
    "\n",
    "        X_data.append(img)\n",
    "    else:\n",
    "        print(f\"Failed to load image: {img_path}\")\n",
    "\n",
    "# X_data now contains the resized and correctly formatted images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67b0354a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_data =[]\n",
    "for file in no_values:\n",
    "    #face = misc.imread('../input/brain_tumor_dataset/yes/'+file)\n",
    "    img = cv2.imread('/Users/alirazi/Desktop/archive/brain_tumor_dataset/no/'+file)\n",
    "    face = cv2.resize(img, (32, 32) )\n",
    "    (b, g, r)=cv2.split(face) \n",
    "    img=cv2.merge([r,g,b])\n",
    "    X_data.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "176c2b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_data)==len(data)==len(data_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8092986",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.squeeze(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5d6e6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 32, 32, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42de387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data\n",
    "X = X.astype('float32')\n",
    "X /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6aa080d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7fd99a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = (X[:190],data_target[:190]) , (X[190:] , data_target[190:])\n",
    "(x_valid , y_valid) = (x_test[:63], y_test[:63])\n",
    "#(x_test, y_test) = (x_test[63:], y_test[63:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bcc35c78",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Must define the input shape in the first layer of the neural network\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39madd(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConv2D(filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m3\u001b[39m))) \n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Must define the input shape in the first layer of the neural network\n",
    "model.add(tf.keras.layers.Conv2D(filters=16,kernel_size=9, padding='same', activation='relu', input_shape=(32,32,3))) \n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Dropout(0.45))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=16,kernel_size=9,padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=36, kernel_size=9, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.15))\n",
    "\n",
    "\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Take a look at the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "859aab2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer=tf.keras.optimizers.Adam(),\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1a941de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "2/2 [==============================] - 1s 266ms/step - loss: 0.6440 - acc: 0.5368 - val_loss: 1.2730 - val_acc: 0.0000e+00\n",
      "Epoch 2/150\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.4941 - acc: 0.8158 - val_loss: 1.0197 - val_acc: 0.0000e+00\n",
      "Epoch 3/150\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.4693 - acc: 0.8158 - val_loss: 1.1577 - val_acc: 0.0000e+00\n",
      "Epoch 4/150\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.4679 - acc: 0.8158 - val_loss: 1.1491 - val_acc: 0.0000e+00\n",
      "Epoch 5/150\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.4664 - acc: 0.8158 - val_loss: 1.0146 - val_acc: 0.0000e+00\n",
      "Epoch 6/150\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 0.4743 - acc: 0.8158 - val_loss: 1.0207 - val_acc: 0.0000e+00\n",
      "Epoch 7/150\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.4631 - acc: 0.8158 - val_loss: 1.0434 - val_acc: 0.0000e+00\n",
      "Epoch 8/150\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.4534 - acc: 0.8158 - val_loss: 1.1282 - val_acc: 0.0000e+00\n",
      "Epoch 9/150\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.4577 - acc: 0.8158 - val_loss: 0.9559 - val_acc: 0.0000e+00\n",
      "Epoch 10/150\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.4566 - acc: 0.8158 - val_loss: 0.9038 - val_acc: 0.0000e+00\n",
      "Epoch 11/150\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.4502 - acc: 0.8158 - val_loss: 1.1667 - val_acc: 0.0000e+00\n",
      "Epoch 12/150\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.4590 - acc: 0.8158 - val_loss: 1.0924 - val_acc: 0.0000e+00\n",
      "Epoch 13/150\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.4482 - acc: 0.8158 - val_loss: 0.9170 - val_acc: 0.0000e+00\n",
      "Epoch 14/150\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.4409 - acc: 0.8158 - val_loss: 1.0224 - val_acc: 0.0000e+00\n",
      "Epoch 15/150\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.4235 - acc: 0.8158 - val_loss: 1.0335 - val_acc: 0.0000e+00\n",
      "Epoch 16/150\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.4173 - acc: 0.8158 - val_loss: 0.9245 - val_acc: 0.0000e+00\n",
      "Epoch 17/150\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.4103 - acc: 0.8158 - val_loss: 0.9163 - val_acc: 0.0000e+00\n",
      "Epoch 18/150\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.4016 - acc: 0.8158 - val_loss: 0.9788 - val_acc: 0.0000e+00\n",
      "Epoch 19/150\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.3969 - acc: 0.8158 - val_loss: 1.0738 - val_acc: 0.0000e+00\n",
      "Epoch 20/150\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.4042 - acc: 0.8158 - val_loss: 0.7819 - val_acc: 0.0000e+00\n",
      "Epoch 21/150\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.4188 - acc: 0.8316 - val_loss: 0.9804 - val_acc: 0.0317\n",
      "Epoch 22/150\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.4063 - acc: 0.8263 - val_loss: 1.1049 - val_acc: 0.0952\n",
      "Epoch 23/150\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.4341 - acc: 0.8263 - val_loss: 0.8160 - val_acc: 0.2540\n",
      "Epoch 24/150\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.3928 - acc: 0.8526 - val_loss: 0.9718 - val_acc: 0.1429\n",
      "Epoch 25/150\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.3773 - acc: 0.8316 - val_loss: 1.1343 - val_acc: 0.0952\n",
      "Epoch 26/150\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 0.3878 - acc: 0.8368 - val_loss: 0.9717 - val_acc: 0.1587\n",
      "Epoch 27/150\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.3945 - acc: 0.8526 - val_loss: 0.8743 - val_acc: 0.3175\n",
      "Epoch 28/150\n",
      "2/2 [==============================] - 0s 176ms/step - loss: 0.3777 - acc: 0.8474 - val_loss: 1.0976 - val_acc: 0.1587\n",
      "Epoch 29/150\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.3661 - acc: 0.8474 - val_loss: 1.0366 - val_acc: 0.1905\n",
      "Epoch 30/150\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.3789 - acc: 0.8474 - val_loss: 0.8459 - val_acc: 0.4762\n",
      "Epoch 31/150\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.3766 - acc: 0.8263 - val_loss: 0.9267 - val_acc: 0.4603\n",
      "Epoch 32/150\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.3488 - acc: 0.8579 - val_loss: 1.0691 - val_acc: 0.3810\n",
      "Epoch 33/150\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.3537 - acc: 0.8632 - val_loss: 1.0258 - val_acc: 0.4127\n",
      "Epoch 34/150\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.3674 - acc: 0.8474 - val_loss: 0.9089 - val_acc: 0.4921\n",
      "Epoch 35/150\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.3477 - acc: 0.8632 - val_loss: 0.9831 - val_acc: 0.4127\n",
      "Epoch 36/150\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.3261 - acc: 0.8579 - val_loss: 0.8353 - val_acc: 0.4762\n",
      "Epoch 37/150\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.3489 - acc: 0.8474 - val_loss: 0.8684 - val_acc: 0.4603\n",
      "Epoch 38/150\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 0.3293 - acc: 0.8632 - val_loss: 0.9710 - val_acc: 0.4444\n",
      "Epoch 39/150\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.3306 - acc: 0.8526 - val_loss: 0.8221 - val_acc: 0.4921\n",
      "Epoch 40/150\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.3309 - acc: 0.8579 - val_loss: 0.7463 - val_acc: 0.5079\n",
      "Epoch 41/150\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.3241 - acc: 0.8737 - val_loss: 1.0913 - val_acc: 0.3492\n",
      "Epoch 42/150\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.3245 - acc: 0.8842 - val_loss: 0.8817 - val_acc: 0.4603\n",
      "Epoch 43/150\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.3318 - acc: 0.8684 - val_loss: 0.7050 - val_acc: 0.5238\n",
      "Epoch 44/150\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.3213 - acc: 0.8789 - val_loss: 1.1830 - val_acc: 0.3651\n",
      "Epoch 45/150\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.3081 - acc: 0.8789 - val_loss: 1.0992 - val_acc: 0.3968\n",
      "Epoch 46/150\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 0.3057 - acc: 0.8737 - val_loss: 0.6894 - val_acc: 0.5238\n",
      "Epoch 47/150\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.3183 - acc: 0.8947 - val_loss: 0.7975 - val_acc: 0.5079\n",
      "Epoch 48/150\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.2898 - acc: 0.8842 - val_loss: 1.2563 - val_acc: 0.3492\n",
      "Epoch 49/150\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.3175 - acc: 0.8789 - val_loss: 1.1090 - val_acc: 0.4444\n",
      "Epoch 50/150\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 0.2775 - acc: 0.9000 - val_loss: 0.7160 - val_acc: 0.5556\n",
      "Epoch 51/150\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.3340 - acc: 0.8684 - val_loss: 0.8590 - val_acc: 0.5079\n",
      "Epoch 52/150\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 0.2755 - acc: 0.8947 - val_loss: 1.2175 - val_acc: 0.3175\n",
      "Epoch 53/150\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.2939 - acc: 0.8842 - val_loss: 1.1515 - val_acc: 0.3651\n",
      "Epoch 54/150\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.2723 - acc: 0.9053 - val_loss: 0.7898 - val_acc: 0.5079\n",
      "Epoch 55/150\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.2704 - acc: 0.8947 - val_loss: 0.8017 - val_acc: 0.5238\n",
      "Epoch 56/150\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.2559 - acc: 0.9053 - val_loss: 1.0774 - val_acc: 0.4921\n",
      "Epoch 57/150\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.2644 - acc: 0.8895 - val_loss: 0.9586 - val_acc: 0.5079\n",
      "Epoch 58/150\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.2405 - acc: 0.9053 - val_loss: 0.7116 - val_acc: 0.5556\n",
      "Epoch 59/150\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.2754 - acc: 0.8632 - val_loss: 0.8383 - val_acc: 0.5238\n",
      "Epoch 60/150\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.2568 - acc: 0.8789 - val_loss: 0.9496 - val_acc: 0.5079\n",
      "Epoch 61/150\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.2585 - acc: 0.9105 - val_loss: 0.9274 - val_acc: 0.5079\n",
      "Epoch 62/150\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.2347 - acc: 0.9105 - val_loss: 0.9415 - val_acc: 0.4762\n",
      "Epoch 63/150\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.2536 - acc: 0.8947 - val_loss: 1.0497 - val_acc: 0.4603\n",
      "Epoch 64/150\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.2366 - acc: 0.8947 - val_loss: 0.9971 - val_acc: 0.4762\n",
      "Epoch 65/150\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.2235 - acc: 0.9211 - val_loss: 1.0149 - val_acc: 0.4762\n",
      "Epoch 66/150\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.2184 - acc: 0.9158 - val_loss: 0.9397 - val_acc: 0.4921\n",
      "Epoch 67/150\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.1855 - acc: 0.9211 - val_loss: 0.9066 - val_acc: 0.5397\n",
      "Epoch 68/150\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.1975 - acc: 0.9211 - val_loss: 1.0182 - val_acc: 0.5397\n",
      "Epoch 69/150\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.2041 - acc: 0.9158 - val_loss: 1.1302 - val_acc: 0.5238\n",
      "Epoch 70/150\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.2097 - acc: 0.9158 - val_loss: 0.8737 - val_acc: 0.5714\n",
      "Epoch 71/150\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.1962 - acc: 0.9263 - val_loss: 0.9020 - val_acc: 0.5238\n",
      "Epoch 72/150\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.1896 - acc: 0.9158 - val_loss: 1.5391 - val_acc: 0.2540\n",
      "Epoch 73/150\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.2497 - acc: 0.8895 - val_loss: 0.7829 - val_acc: 0.5556\n",
      "Epoch 74/150\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.2309 - acc: 0.9158 - val_loss: 1.4262 - val_acc: 0.3016\n",
      "Epoch 75/150\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.2091 - acc: 0.8947 - val_loss: 1.0801 - val_acc: 0.5079\n",
      "Epoch 76/150\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.1725 - acc: 0.9263 - val_loss: 0.8206 - val_acc: 0.5873\n",
      "Epoch 77/150\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.1635 - acc: 0.9263 - val_loss: 1.6251 - val_acc: 0.4444\n",
      "Epoch 78/150\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.2261 - acc: 0.9105 - val_loss: 1.0138 - val_acc: 0.5556\n",
      "Epoch 79/150\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.1469 - acc: 0.9474 - val_loss: 0.6207 - val_acc: 0.6508\n",
      "Epoch 80/150\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.1767 - acc: 0.9474 - val_loss: 1.0302 - val_acc: 0.5079\n",
      "Epoch 81/150\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.1561 - acc: 0.9368 - val_loss: 1.2919 - val_acc: 0.4444\n",
      "Epoch 82/150\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.1501 - acc: 0.9474 - val_loss: 0.8960 - val_acc: 0.6190\n",
      "Epoch 83/150\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.1196 - acc: 0.9526 - val_loss: 1.0224 - val_acc: 0.6032\n",
      "Epoch 84/150\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.1271 - acc: 0.9368 - val_loss: 2.0558 - val_acc: 0.3492\n",
      "Epoch 85/150\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.1759 - acc: 0.9211 - val_loss: 1.4342 - val_acc: 0.4762\n",
      "Epoch 86/150\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.1754 - acc: 0.9211 - val_loss: 0.7494 - val_acc: 0.6508\n",
      "Epoch 87/150\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.1843 - acc: 0.9316 - val_loss: 1.6870 - val_acc: 0.3016\n",
      "Epoch 88/150\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.1841 - acc: 0.9158 - val_loss: 1.5705 - val_acc: 0.4286\n",
      "Epoch 89/150\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.0989 - acc: 0.9526 - val_loss: 1.0960 - val_acc: 0.5556\n",
      "Epoch 90/150\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.1149 - acc: 0.9579 - val_loss: 1.0808 - val_acc: 0.5556\n",
      "Epoch 91/150\n",
      "2/2 [==============================] - 0s 175ms/step - loss: 0.1675 - acc: 0.9316 - val_loss: 1.7700 - val_acc: 0.4444\n",
      "Epoch 92/150\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.1449 - acc: 0.9474 - val_loss: 1.8169 - val_acc: 0.4127\n",
      "Epoch 93/150\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.1159 - acc: 0.9421 - val_loss: 1.1563 - val_acc: 0.5873\n",
      "Epoch 94/150\n",
      "2/2 [==============================] - 0s 182ms/step - loss: 0.1254 - acc: 0.9579 - val_loss: 0.8700 - val_acc: 0.6508\n",
      "Epoch 95/150\n",
      "2/2 [==============================] - 0s 176ms/step - loss: 0.1413 - acc: 0.9526 - val_loss: 1.3419 - val_acc: 0.5556\n",
      "Epoch 96/150\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.0781 - acc: 0.9737 - val_loss: 1.6291 - val_acc: 0.5238\n",
      "Epoch 97/150\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.0809 - acc: 0.9632 - val_loss: 1.2475 - val_acc: 0.6032\n",
      "Epoch 98/150\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.0941 - acc: 0.9579 - val_loss: 1.1994 - val_acc: 0.6349\n",
      "Epoch 99/150\n",
      "2/2 [==============================] - 0s 216ms/step - loss: 0.0959 - acc: 0.9579 - val_loss: 1.8512 - val_acc: 0.4762\n",
      "Epoch 100/150\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.0556 - acc: 0.9842 - val_loss: 2.2335 - val_acc: 0.4286\n",
      "Epoch 101/150\n",
      "2/2 [==============================] - 0s 173ms/step - loss: 0.1007 - acc: 0.9368 - val_loss: 1.3157 - val_acc: 0.6190\n",
      "Epoch 102/150\n",
      "2/2 [==============================] - 0s 174ms/step - loss: 0.1149 - acc: 0.9474 - val_loss: 1.2575 - val_acc: 0.6190\n",
      "Epoch 103/150\n",
      "2/2 [==============================] - 0s 175ms/step - loss: 0.0950 - acc: 0.9579 - val_loss: 1.8944 - val_acc: 0.5714\n",
      "Epoch 104/150\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 0.0899 - acc: 0.9474 - val_loss: 1.8758 - val_acc: 0.5714\n",
      "Epoch 105/150\n",
      "2/2 [==============================] - 0s 171ms/step - loss: 0.0691 - acc: 0.9789 - val_loss: 1.5004 - val_acc: 0.6032\n",
      "Epoch 106/150\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.0607 - acc: 0.9789 - val_loss: 1.5873 - val_acc: 0.6032\n",
      "Epoch 107/150\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.0438 - acc: 0.9895 - val_loss: 1.7959 - val_acc: 0.5714\n",
      "Epoch 108/150\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.0591 - acc: 0.9842 - val_loss: 1.9032 - val_acc: 0.5714\n",
      "Epoch 109/150\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.0388 - acc: 0.9895 - val_loss: 1.8471 - val_acc: 0.5873\n",
      "Epoch 110/150\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.0521 - acc: 0.9737 - val_loss: 2.0237 - val_acc: 0.5556\n",
      "Epoch 111/150\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.0478 - acc: 0.9842 - val_loss: 1.8613 - val_acc: 0.5873\n",
      "Epoch 112/150\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.0646 - acc: 0.9684 - val_loss: 1.7337 - val_acc: 0.6349\n",
      "Epoch 113/150\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.0580 - acc: 0.9789 - val_loss: 1.9929 - val_acc: 0.5556\n",
      "Epoch 114/150\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 0.0266 - acc: 0.9947 - val_loss: 1.8500 - val_acc: 0.5714\n",
      "Epoch 115/150\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.0577 - acc: 0.9737 - val_loss: 1.9914 - val_acc: 0.5873\n",
      "Epoch 116/150\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.0742 - acc: 0.9789 - val_loss: 1.7395 - val_acc: 0.5873\n",
      "Epoch 117/150\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.0509 - acc: 0.9737 - val_loss: 1.4965 - val_acc: 0.6508\n",
      "Epoch 118/150\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.0255 - acc: 0.9842 - val_loss: 1.9279 - val_acc: 0.6190\n",
      "Epoch 119/150\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.0485 - acc: 0.9895 - val_loss: 2.1078 - val_acc: 0.6032\n",
      "Epoch 120/150\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.0276 - acc: 0.9895 - val_loss: 1.9959 - val_acc: 0.6032\n",
      "Epoch 121/150\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.0274 - acc: 1.0000 - val_loss: 1.9216 - val_acc: 0.6190\n",
      "Epoch 122/150\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.0375 - acc: 0.9842 - val_loss: 2.3130 - val_acc: 0.5873\n",
      "Epoch 123/150\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.0371 - acc: 0.9737 - val_loss: 2.4629 - val_acc: 0.5556\n",
      "Epoch 124/150\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.0336 - acc: 0.9842 - val_loss: 2.0488 - val_acc: 0.6032\n",
      "Epoch 125/150\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.0261 - acc: 0.9947 - val_loss: 1.7749 - val_acc: 0.6032\n",
      "Epoch 126/150\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.0296 - acc: 0.9947 - val_loss: 2.0537 - val_acc: 0.6032\n",
      "Epoch 127/150\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.0152 - acc: 1.0000 - val_loss: 2.6134 - val_acc: 0.5556\n",
      "Epoch 128/150\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.0273 - acc: 0.9842 - val_loss: 2.5726 - val_acc: 0.5714\n",
      "Epoch 129/150\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.0267 - acc: 0.9895 - val_loss: 2.3982 - val_acc: 0.6032\n",
      "Epoch 130/150\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.0317 - acc: 0.9947 - val_loss: 2.5477 - val_acc: 0.5873\n",
      "Epoch 131/150\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.0201 - acc: 0.9842 - val_loss: 2.4499 - val_acc: 0.5873\n",
      "Epoch 132/150\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.0429 - acc: 0.9789 - val_loss: 2.0505 - val_acc: 0.6032\n",
      "Epoch 133/150\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.0463 - acc: 0.9842 - val_loss: 2.2196 - val_acc: 0.5873\n",
      "Epoch 134/150\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.0211 - acc: 0.9947 - val_loss: 2.6308 - val_acc: 0.5238\n",
      "Epoch 135/150\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.0175 - acc: 0.9947 - val_loss: 2.6537 - val_acc: 0.4921\n",
      "Epoch 136/150\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.0297 - acc: 0.9895 - val_loss: 1.9891 - val_acc: 0.5873\n",
      "Epoch 137/150\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.0337 - acc: 0.9842 - val_loss: 1.9315 - val_acc: 0.6032\n",
      "Epoch 138/150\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.0246 - acc: 0.9947 - val_loss: 2.0026 - val_acc: 0.5714\n",
      "Epoch 139/150\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.0107 - acc: 1.0000 - val_loss: 2.1574 - val_acc: 0.5397\n",
      "Epoch 140/150\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.0468 - acc: 0.9842 - val_loss: 2.4046 - val_acc: 0.5238\n",
      "Epoch 141/150\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.0418 - acc: 0.9895 - val_loss: 2.2243 - val_acc: 0.5556\n",
      "Epoch 142/150\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.0176 - acc: 0.9947 - val_loss: 1.9946 - val_acc: 0.5873\n",
      "Epoch 143/150\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.0159 - acc: 0.9947 - val_loss: 2.0750 - val_acc: 0.5873\n",
      "Epoch 144/150\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.0313 - acc: 0.9895 - val_loss: 2.1773 - val_acc: 0.5873\n",
      "Epoch 145/150\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.0320 - acc: 0.9947 - val_loss: 2.4093 - val_acc: 0.5873\n",
      "Epoch 146/150\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.0174 - acc: 0.9947 - val_loss: 2.4469 - val_acc: 0.5556\n",
      "Epoch 147/150\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.0127 - acc: 1.0000 - val_loss: 2.4029 - val_acc: 0.5714\n",
      "Epoch 148/150\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.0192 - acc: 0.9947 - val_loss: 2.4913 - val_acc: 0.5397\n",
      "Epoch 149/150\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.3832 - val_acc: 0.5714\n",
      "Epoch 150/150\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.0523 - acc: 0.9789 - val_loss: 1.6170 - val_acc: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f9bb5ca3970>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,\n",
    "         y_train,\n",
    "         batch_size=128,\n",
    "         epochs=150,\n",
    "         validation_data=(x_valid, y_valid),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d2efc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-21 01:58:47.948706: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_model\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming 'model' is your Keras model\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m plot_model(\u001b[43mmodel\u001b[49m, show_shapes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, to_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "\n",
    "# Assuming 'model' is your Keras model\n",
    "plot_model(model, show_shapes=True, to_file='model.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a550971",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "SVG(model_to_dot(model,show_shapes = True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "974c1cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Specify the directory path\n",
    "img_path = '/Users/alirazi/Desktop/archive/brain_tumor_datasetNO_Tumor'\n",
    "\n",
    "classes = { 'No_Tumor': 0, 'Yes_Tumor': 1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5b4b341b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/alirazi/Desktop/archive/brain_tumor_datasetNo_Tumor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m classes:\n\u001b[1;32m      7\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/alirazi/Desktop/archive/brain_tumor_dataset\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m\u001b[38;5;28mcls\u001b[39m\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      9\u001b[0m         img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(img_path\u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mj,\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     10\u001b[0m         img \u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mresize(img,(\u001b[38;5;241m200\u001b[39m,\u001b[38;5;241m200\u001b[39m))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/alirazi/Desktop/archive/brain_tumor_datasetNo_Tumor'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "img_path =os.listdir('/Users/alirazi/Desktop/archive/brain_tumor_dataset/')\n",
    "for cls in classes:\n",
    "    img_path = '/Users/alirazi/Desktop/archive/brain_tumor_dataset' +cls\n",
    "    for j in os.listdir(img_path):\n",
    "        img = cv2.imread(img_path+ '/'+j,0)\n",
    "        img =cv2.resize(img,(200,200))\n",
    "        X.append(img)\n",
    "        Y.append(classes[cls])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0b5b6d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images loaded: 0\n",
      "No images loaded.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the dataset directory\n",
    "DATASET_DIR = '/Users/alirazi/Desktop/archive/brain_tumor_dataset/TRAIN'\n",
    "\n",
    "# Define the class mapping\n",
    "classes = {'NO_Tumor': 0, 'Yes_Tumor': 1}\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "# Iterate through each class\n",
    "for cls, label in classes.items():\n",
    "    class_path = os.path.join(DATASET_DIR, cls)  # Construct the class-specific directory path\n",
    "    \n",
    "    # Check if the class directory exists\n",
    "    if os.path.exists(class_path):\n",
    "        print(f\"Loading images for class: {cls}\")\n",
    "        for image_filename in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, image_filename)  # Construct the full image path\n",
    "            \n",
    "            try:\n",
    "                img = cv2.imread(img_path, 0)  # Read the image in grayscale (0)\n",
    "                \n",
    "                if img is not None:\n",
    "                    img = cv2.resize(img, (200, 200))  # Resize the image\n",
    "                    X.append(img)\n",
    "                    Y.append(label)  # Use 'label' to specify the class label\n",
    "                else:\n",
    "                    print(f\"Skipping invalid image: {img_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image: {img_path}\")\n",
    "                print(str(e))\n",
    "\n",
    "# Now, X contains the images and Y contains the corresponding labels\n",
    "print(f\"Number of images loaded: {len(X)}\")\n",
    "\n",
    "# Visualize the first image if available\n",
    "if len(X) > 0:\n",
    "    plt.imshow(X[0], cmap='gray')\n",
    "    plt.title(f\"Class: {Y[0]}\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No images loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ea4755a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "IMG_PATH = '/Users/alirazi/Desktop/archive/brain_tumor_dataset/'\n",
    "\n",
    "# Define the target directories\n",
    "TRAIN_DIR = 'TRAIN'\n",
    "VAL_DIR = 'VAL'\n",
    "TEST_DIR = 'TEST'\n",
    "\n",
    "# Create target directories if they don't exist\n",
    "os.makedirs(TRAIN_DIR, exist_ok=True)\n",
    "os.makedirs(VAL_DIR, exist_ok=True)\n",
    "os.makedirs(TEST_DIR, exist_ok=True)\n",
    "\n",
    "# Process each file individually\n",
    "for CLASS in os.listdir(IMG_PATH):\n",
    "    class_path = os.path.join(IMG_PATH, CLASS)\n",
    "\n",
    "    if not CLASS.startswith('.') and os.path.isdir(class_path):\n",
    "        for FILE_NAME in os.listdir(class_path):\n",
    "            img = os.path.join(class_path, FILE_NAME)\n",
    "\n",
    "            # Determine the destination directory based on your conditions\n",
    "            if FILE_NAME.startswith('y'):\n",
    "                # Move to TRAIN if it starts with 'y'\n",
    "                shutil.copy(img, os.path.join(TRAIN_DIR, FILE_NAME))\n",
    "            elif FILE_NAME.startswith('n'):\n",
    "                # Move to VAL if it starts with 'n'\n",
    "                shutil.copy(img, os.path.join(VAL_DIR, FILE_NAME))\n",
    "            else:\n",
    "                # Move to TEST for other cases\n",
    "                shutil.copy(img, os.path.join(TEST_DIR, FILE_NAME))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8a848fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "IMG_PATH = '/Users/alirazi/Desktop/archive/brain_tumor_dataset/'\n",
    "\n",
    "# Define the target directories\n",
    "TRAIN_DIR = 'TRAIN'\n",
    "VAL_DIR = 'VAL'\n",
    "TEST_DIR = 'TEST'\n",
    "\n",
    "# Create target directories if they don't exist\n",
    "os.makedirs(TRAIN_DIR, exist_ok=True)\n",
    "os.makedirs(VAL_DIR, exist_ok=True)\n",
    "os.makedirs(TEST_DIR, exist_ok=True)\n",
    "\n",
    "# Process each file individually\n",
    "for CLASS in os.listdir(IMG_PATH):\n",
    "    class_path = os.path.join(IMG_PATH, CLASS)\n",
    "\n",
    "    if not CLASS.startswith('.') and os.path.isdir(class_path):\n",
    "        # Create subdirectories for each class in TRAIN, VAL, and TEST\n",
    "        os.makedirs(os.path.join(TRAIN_DIR, CLASS), exist_ok=True)\n",
    "        os.makedirs(os.path.join(VAL_DIR, CLASS), exist_ok=True)\n",
    "        os.makedirs(os.path.join(TEST_DIR, CLASS), exist_ok=True)\n",
    "\n",
    "        # List all files in the class directory\n",
    "        files = os.listdir(class_path)\n",
    "        num_files = len(files)\n",
    "        \n",
    "        # Determine the number of files for VAL and TEST (you can adjust these percentages)\n",
    "        val_percentage = 0.1  # 10% for validation\n",
    "        test_percentage = 0.1  # 10% for testing\n",
    "\n",
    "        val_count = int(num_files * val_percentage)\n",
    "        test_count = int(num_files * test_percentage)\n",
    "\n",
    "        for i, FILE_NAME in enumerate(files):\n",
    "            img = os.path.join(class_path, FILE_NAME)\n",
    "\n",
    "            # Determine the destination directory based on the count\n",
    "            if i < val_count:\n",
    "                shutil.copy(img, os.path.join(VAL_DIR, CLASS, FILE_NAME))\n",
    "            elif i < val_count + test_count:\n",
    "                shutil.copy(img, os.path.join(TEST_DIR, CLASS, FILE_NAME))\n",
    "            else:\n",
    "                shutil.copy(img, os.path.join(TRAIN_DIR, CLASS, FILE_NAME))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5020c70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'TRAIN'\n",
    "VAL_DIR = 'VAL'\n",
    "TEST_DIR = 'TEST'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee87ef94",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = 128\n",
    "IMAGE_HEIGHT = 128\n",
    "BATCH_SIZE = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5d3f700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 203 images belonging to 3 classes.\n",
      "Found 25 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation for training dataset\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Generator for training dataset\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary'  # Assuming binary classification (yes/no)\n",
    ")\n",
    "\n",
    "# Preprocessing for validation and test datasets\n",
    "val_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e941dbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # Output layer with sigmoid activation for binary classification\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e30fbcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2387332a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 4s 369ms/step - loss: 0.1149 - accuracy: 0.9015 - val_loss: 5.1753e-21 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 2s 379ms/step - loss: 2.3936e-16 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 2s 371ms/step - loss: 2.0182e-24 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 2s 320ms/step - loss: 1.4244e-29 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 3s 343ms/step - loss: 9.7130e-37 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 3s 376ms/step - loss: 3.7859e-37 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 3s 343ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 2s 328ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 3s 430ms/step - loss: 4.4198e-38 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 3s 336ms/step - loss: 1.3130e-37 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=10,  # You can adjust the number of epochs\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(val_generator)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c92eb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25 images belonging to 3 classes.\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Test accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Generator for the test dataset\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "\n",
    "print(f\"Test accuracy: {test_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e6de91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
